{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5c4367",
   "metadata": {},
   "source": [
    "# Smiles Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b266b6",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73576935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CSV_PATH = \"./datasets/spotify_churn_dataset.csv\"  \n",
    "TARGET_COL = \"is_churned\"                 \n",
    "ID_COL = \"user_id\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 140)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read raw (let pandas infer, then coerce precisely)\n",
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Make a copy to work with\n",
    "df = df_raw.copy()\n",
    "\n",
    "# --- Coerce types explicitly for this schema ---\n",
    "# Categorical/text\n",
    "cat_cols_expected = [\"gender\", \"country\", \"subscription_type\", \"device_type\"]\n",
    "for c in cat_cols_expected:\n",
    "    if c in df.columns:\n",
    "        df[c] = (\n",
    "            df[c]\n",
    "            .astype(\"string\")\n",
    "            .str.strip()\n",
    "        )\n",
    "\n",
    "# Numeric\n",
    "num_cols_expected = [\n",
    "    \"age\",\n",
    "    \"listening_time\",\n",
    "    \"songs_played_per_day\",\n",
    "    \"skip_rate\",\n",
    "    \"ads_listened_per_week\",\n",
    "]\n",
    "for c in num_cols_expected:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# ID (keep as nullable integer for safety; exclude from modeling later)\n",
    "if ID_COL in df.columns:\n",
    "    df[ID_COL] = pd.to_numeric(df[ID_COL], errors=\"coerce\").astype(\"Int64\")\n",
    "    print(f\"[info] Found ID column: {ID_COL}\")\n",
    "\n",
    "# offline_listening comes as 0/1 -> boolean\n",
    "if \"offline_listening\" in df.columns:\n",
    "    df[\"offline_listening\"] = (\n",
    "        pd.to_numeric(df[\"offline_listening\"], errors=\"coerce\")\n",
    "          .map({1: True, 0: False})\n",
    "          .astype(\"boolean\")\n",
    "    )\n",
    "\n",
    "# Target (is_churned) as 0/1 -> int, keep NaN if weird values appear\n",
    "if TARGET_COL in df.columns:\n",
    "    y_tmp = pd.to_numeric(df[TARGET_COL], errors=\"coerce\")\n",
    "    bad = y_tmp.isna().sum()\n",
    "    if bad > 0:\n",
    "        print(f\"[warn] {bad} rows in '{TARGET_COL}' could not be parsed as 0/1 (will be NaN).\")\n",
    "    df[TARGET_COL] = y_tmp.astype(\"Int64\")\n",
    "else:\n",
    "    print(f\"[warn] Target column '{TARGET_COL}' not found.\")\n",
    "\n",
    "print(f\"[loaded] {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "display(df.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8d04db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: overview & missing-safe ---\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "print(f\"Rows: {df.shape[0]} | Columns: {df.shape[1]}\")\n",
    "df.info()  # don't wrap with display(); it returns None\n",
    "\n",
    "# Descriptive stats (numeric only)\n",
    "print(\"\\nNumeric summary:\")\n",
    "display(df.select_dtypes(include=\"number\").describe().T)\n",
    "\n",
    "# Categorical quick peek (top categories)\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "if cat_cols:\n",
    "    print(\"\\nCategorical top values (first 5 cols):\")\n",
    "    for c in cat_cols[:5]:\n",
    "        print(f\"\\n[{c}]\")\n",
    "        display(df[c].value_counts(dropna=False).head(10))\n",
    "\n",
    "# Missing values (safe if none)\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "has_missing = (missing > 0).any()\n",
    "if has_missing:\n",
    "    print(\"\\nMissing values found:\")\n",
    "    display(missing[missing > 0])\n",
    "\n",
    "    plt.figure(figsize=(7,4))\n",
    "    missing[missing > 0].sort_values().plot.barh()\n",
    "    plt.title(\"Missing values per column\")\n",
    "    plt.xlabel(\"Fraction of missing\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n[OK] No missing values detected. Skipping missing-values plot.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213ef81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# --- 4.1  Check churn balance ---\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COL}' not found.\")\n",
    "\n",
    "churn_rate = df[TARGET_COL].mean()\n",
    "print(f\"[INFO] Churn rate: {churn_rate:.2%}\")\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "sns.countplot(x=TARGET_COL, data=df)\n",
    "plt.title(f\"Churn distribution (rate â‰ˆ {churn_rate:.1%})\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 4.2  Numeric features vs churn ---\n",
    "num_cols = df.select_dtypes(include=[\"number\"]).columns.drop([TARGET_COL, \"user_id\"], errors=\"ignore\")\n",
    "\n",
    "print(f\"Numeric columns: {list(num_cols)}\")\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.histplot(data=df, x=col, hue=TARGET_COL, kde=True, bins=30, element=\"step\")\n",
    "    plt.title(f\"{col} by churn status\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- 4.3  Categorical features vs churn (bar charts) ---\n",
    "cat_cols = df.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist() + \\\n",
    "           df.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "\n",
    "for col in cat_cols:\n",
    "    if df[col].nunique(dropna=True) <= 15:  # avoid overcrowding\n",
    "        plt.figure(figsize=(6,3))\n",
    "        sns.barplot(\n",
    "            data=df,\n",
    "            x=col, y=TARGET_COL,\n",
    "            estimator=np.mean,\n",
    "            order=df[col].value_counts().index\n",
    "        )\n",
    "        plt.title(f\"Mean churn rate by {col}\")\n",
    "        plt.xticks(rotation=30, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672faf9",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfc7f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGET_COL = \"is_churned\"\n",
    "ID_COL = \"user_id\"\n",
    "\n",
    "# --- 5.1 Separate target and drop ID ---\n",
    "X = df.drop(columns=[TARGET_COL, ID_COL], errors=\"ignore\")\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# --- 5.2 Split train/test (keep churn proportion consistent) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape} | Test: {X_test.shape}\")\n",
    "print(f\"Churn rate train = {y_train.mean():.2%} | test = {y_test.mean():.2%}\")\n",
    "\n",
    "# --- 5.3 Identify column types (for preprocessing) ---\n",
    "num_cols = X_train.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "cat_cols = X_train.select_dtypes(include=[\"object\", \"string\", \"category\"]).columns.tolist()\n",
    "bool_cols = X_train.select_dtypes(include=[\"bool\"]).columns.tolist()\n",
    "\n",
    "print(\"\\nNumeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols)\n",
    "print(\"Boolean cols:\", bool_cols)\n",
    "\n",
    "# --- optional: ensure bool â†’ int for modeling simplicity ---\n",
    "for c in bool_cols:\n",
    "    X_train[c] = X_train[c].astype(int)\n",
    "    X_test[c] = X_test[c].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf5a5ba",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae95e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# --- define preprocessing ---\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_cols),\n",
    "        (\"cat\", categorical_transformer, cat_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# --- define models ---\n",
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42, max_depth=None),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n",
    "    \"ANN\": MLPClassifier(hidden_layer_sizes=(64, 32), activation=\"relu\", max_iter=300, random_state=42)\n",
    "}\n",
    "\n",
    "# --- train & evaluate each ---\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nðŸ§  Training {name} ...\")\n",
    "    pipe = Pipeline(steps=[(\"preprocess\", preprocessor),\n",
    "                           (\"model\", model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # predictions (use the PIPELINE, not the bare model)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    # probabilities / scores (again from the PIPELINE)\n",
    "    try:\n",
    "        y_prob = pipe.predict_proba(X_test)[:, 1]\n",
    "    except AttributeError:\n",
    "        # e.g., SVM without probas (or any model lacking predict_proba)\n",
    "        if hasattr(pipe, \"decision_function\"):\n",
    "            scores = pipe.decision_function(X_test)\n",
    "            # min-max normalize to [0,1] for ROC-AUC\n",
    "            y_prob = (scores - scores.min()) / (scores.max() - scores.min() + 1e-9)\n",
    "        else:\n",
    "            # fallback: cast preds to float\n",
    "            y_prob = y_pred.astype(float)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "    except ValueError:\n",
    "        # If only one class in y_test (rare), fall back to accuracy as proxy\n",
    "        auc = np.nan\n",
    "\n",
    "    print(f\"Accuracy: {acc:.3f} | ROC-AUC: {auc if not np.isnan(auc) else 'NA'}\")\n",
    "    print(classification_report(y_test, y_pred, digits=3))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    results.append({\"Model\": name, \"Accuracy\": acc, \"ROC-AUC\": auc})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"ROC-AUC\", ascending=False, na_position=\"last\")\n",
    "display(results_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
